"""
Smol-Quant Terminal Interface & Safety Pipeline.

This script acts as the primary entry point for the terminal-based interaction
with the Smol-Quant financial agent. It implements a safety-critical architecture
utilizing an LLM-based Evaluator to enforce financial compliance before displaying
results to the user.

Key Features:
1.  LM-as-a-Judge: A distinct LLM instance validates agent outputs against strict compliance rules
2.  Self-Correction Loop: Upon validation failure, feedback is injected back into the agent's context, triggering an autonomous retry
"""

import logging
import os
import sys
from dotenv import load_dotenv
from openai import OpenAI

# Import the agent factory function
from agent.agent_builder import build_agent 

# Load environment variables (API keys, configuration)
load_dotenv()

# Configure logging to track conversation flow and tool usage at the INFO level
logging.basicConfig(level=logging.INFO)

# Instantiate a dedicated client for the Evaluator to decouple safety checks from agent logic
judge_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def evaluator_check(agent_response: str, original_question: str) -> dict:
    """
    Validates agent outputs using the 'LLM-as-a-Judge' pattern.

    Uses GPT-4o-mini acting as a Compliance Officer to
    audit responses for:
    1. Financial Advice violations (imperative commands).
    2. Data Quality issues (hallucinations or empty responses).

    Args:
        agent_response (str): The text output generated by the financial agent.
        original_question (str): The initial query provided by the user.

    Returns:
        dict: A dictionary containing:
            - 'passed' (bool): True if the response is compliant.
            - 'feedback' (str): Detailed explanation of failure if applicable.
    """
    # Define compliance rules for the evaluator, permitting analysis but forbidding directives
    system_prompt = """
    You are a helpful Compliance Assistant checking a financial report.
    
    Review the AI's response based on these Rules:
    
    1. ALLOW ANALYSIS: The AI IS ALLOWED to describe trends, growth, and positive/negative sentiment (e.g., "The stock is performing well", "Strong upside potential", "Investors are bullish"). This is NOT financial advice, it is analysis.
    2. ALLOW IMAGE-ONLY OUTPUTS: The AI IS ALLOWED to give answers that consist of only an image link. In ONLY these cases, no additional information needs to be provided.
    3. NO DIRECT COMMANDS: The AI should only avoid direct imperatives like "Buy this stock now!", "Sell immediately!", or "Put all your money in X".
    4. DATA QUALITY: The answer must not be empty or obvious gibberish. Technical terms like 'np.float64' are acceptable.
    
    Output format strictly:
    PASSED
    (or)
    FAILED: <Reason>
    """
    
    try:
        # Invoke the evaluator model
        response = judge_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"User Question: {original_question}\n\nAI Response: {agent_response}"}
            ]
        )
        
        # Parse the evaluator's decision
        verdict = response.choices[0].message.content
        
        if "PASSED" in verdict:
            return {"passed": True, "feedback": ""}
        else:
            # Extract the rejection reason for the feedback loop
            return {"passed": False, "feedback": verdict.replace("FAILED:", "").strip()}
            
    except Exception as e:
        # specific fallback to prevent system lockup on evaluator failure
        return {"passed": True, "feedback": f"Judge Error (Passed by default): {e}"}

def run_safe_pipeline(agent, user_input: str) -> str:
    """
    Orchestrates the agent execution within a compliance-driven self-correction loop.

    1. Generates an initial response.
    2. Evaluates the response against safety protocols.
    3. If rejected, injects feedback into the agent's memory for iterative correction.

    Args:
        agent: The initialized CodeAgent instance.
        user_input (str): The user's query.

    Returns:
        str: The final, compliant text response or a fallback error message.
    """
    print(f"[Agent] Processing query...")
    
    # Execute initial query, reset=True clears prior context to ensure a fresh start 
    response = agent.run(user_input, reset=True)
    
    # Set retry limit to prevent infinite correction loops
    max_retries = 3
    
    for attempt in range(max_retries):
        # Ensure response is string-formatted for evaluation
        response_str = str(response)
        
        # Assess compliance of the generated response
        evaluation = evaluator_check(response_str, user_input)
        
        if evaluation["passed"]:
            print(f"Compliance Check Passed (Attempt {attempt+1})")
            return response # Exit loop on success
        
        # Process failed validation
        print(f"\n[Warning] Compliance Alert (Attempt {attempt+1}/{max_retries}): {evaluation['feedback']}")
        print("[System] Initiating self-correction sequence based on feedback...")
        
        # Construct feedback prompt with specific rejection reasons
        correction_prompt = (
            f"Your previous answer was rejected by the Compliance Officer. "
            f"Reason: {evaluation['feedback']}. "
            f"Please rewrite your answer, strictly following the rules (Data only, no advice)."
        )
        
        # Re-run agent with feedback. reset=False preserves context, enabling iterative improvement
        response = agent.run(correction_prompt, reset=False)

    # Return fallback message if correction limit is reached
    return "[Error] I apologize, but I cannot provide a compliant answer to this query at the moment."

def main():
    """
    Application entry point.
    Initializes the agent architecture and manages the interactive REPL session.
    """
    print("--------------------------------------------------")
    print("Smol-Quant Terminal Interface")
    print("--------------------------------------------------")
    print("Loading Agent and Tools... please wait.")
    
    try:
        # Build the complete agent system (RAG, EDA, ImageGen). This is a one-time cost.
        agent = build_agent()
        print("[System] Ready. (Type 'exit' or 'quit' to close)")
    except Exception as e:
        print(f"[Critical Error] Failed to initialize agent: {e}")
        return

    # Main interaction loop
    while True:
        try:
            print("\n" + "="*50)
            user_input = input("You: ").strip()

            # Handle exit commands
            if user_input.lower() in ["exit", "quit", "q"]:
                print("[System] Session ended.")
                break

            if not user_input:
                continue
            
            # Execute the safe pipeline (Generation + Evaluation + Correction)
            final_response = run_safe_pipeline(agent, user_input)

            print(f"\n[Agent] Final Answer:\n{final_response}")

        except KeyboardInterrupt:
            # Graceful shutdown on CTRL+C
            print("\n[System] Aborted by user.")
            break
        except Exception as e:
            print(f"[Runtime Error] An unexpected error occurred: {e}")

if __name__ == "__main__":
    main()