# Imports
import os
from typing import List
from smolagents import Tool
from pathlib import Path
from dotenv import load_dotenv
from openai import OpenAI
import numpy as np
from scipy.spatial.distance import cosine
import requests

# ------------------------------------------------------------
# Setup
# ------------------------------------------------------------

# Load API key from .env file
env_path = Path(".") / ".env"
load_dotenv(env_path)
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ------------------------------------------------------------
# Helper Functions
# ------------------------------------------------------------

def generate_image_prompt(article_summary: str) -> str:
    """
    Image Prompt Generator

    Converts a news article summary (input) into an image generation prompt (output) via an LLM call (gpt-3.5-turbo).
    Output size is limited and usage of real names is forbidden to improve the quality of images generated from the prompts.
    """
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": """You are a helpful research assistant.
            You will be presented with the summary of a news article.
            Your task is to generate a highly specific and visual prompt based on this summary.
            Generate only the prompt itself, no greetings or commentary.
            Keep it concise (max 30 tokens).
            Do not mention or reference any real-world people, companies, brands, trademarks, or geopolitical events.
            Only use fictional names, organizations, locations, and events."""},
            # Prompts with real company names usually resulted in very abstract images.
            # Therefore, the "only fictional" part was added to the prompt.
            {"role": "user", "content": f"Article summary:\n{article_summary}\n\nGenerate an image prompt:"}
        ]
    )
    return response.choices[0].message.content

def generate_image(prompt: str) -> str:
    """
    Image Generator

    Generates an image based on the prompt from "generate_image_prompt" via Dall-E.
    Dall-E returns a URL, not an actual image file.
    """
    result = client.images.generate(
        model="dall-e-3",
        prompt=prompt,
        size="1024x1024"
    )
    url = result.data[0].url
    if url is None:
        raise RuntimeError("Image API returned no image URL!")
    return url

def describe_image(image_url: str) -> str:
    """
    Image Description Generator

    Describes an image generated by "generate_image" via an LLM call (gpt-4o-mini).
    Text length is limited to keep the descriptions similar to the image prompt.
    This description is later compared to the original prompt in order to rate the image ("rate_image").
    """
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": "Describe this image in 1-2 concise sentences. Only focus on key features, do not exceed 50 tokens."},
                    {"type": "image_url", "image_url": {"url": image_url}}
                ]
            }
        ]
    )
    content = response.choices[0].message.content
    if isinstance(content, list):
        return "".join([c.get("text", "") for c in content])
    return content

def embed_text(text: str) -> np.ndarray:
    """
    Text Embedding

    Returns an embedding vector (text-embedding-3-small) for a given text.
    Here, it is used to create embeddings for:
    1. The original image generation prompt created by "generate_image_prompt"
    2. The description of an image generated from this prompt, created by "describe_image"

    These embeddings are then used to compute a similarity score ("cosine_similarity"),
    which is used to rate the image in question ("rate_image").
    """
    emb = client.embeddings.create(
        model="text-embedding-3-small",
        input=text
    ).data[0].embedding
    return np.array(emb)

def cosine_similarity(vec1: np.ndarray, vec2: np.ndarray) -> float:
    """
    Cosine Similarity

    Returns the cosine similarity between two vectors.
    It is computed by subtracting the cosine distance (implemented in SciPy) from 1.
    Since the cosine distance can range from 0 (identical) to 2 (opposite),
    the cosine similarity scores will fall between 1 (identical) and -1 (opposite).
    The point of this method is to have a scoring system where "high = good".
    Here, it is used to compare the embeddings (generated by "embed_text") of:
    1. The original image generation prompt created by "generate_image_prompt"
    2. The descriptions of an image generated from this prompt, created by "describe_image"

    The cosine similarity is then used to rate the image (see "rate_image").
    """
    return 1 - cosine(vec1, vec2)

def rate_image(prompt: str, image_url: str) -> float:
    """
    Image Rating

    Rates how well an image matches the generation prompt used for it.
    For this, it uses cosine similarities computed by "cosine_similarity".
    These similarities range from 1 (identical) to -1 (opposite).
    "rate_image" multiplies these similarities by 10 and turns negative values to 0.
    The point of this method is to create a scoring system that's intuitive for any user.
    In testing, it typically produced scores roughly in the 6/10 - 8/10 range.
    """
    description = describe_image(image_url)
    prompt_emb = embed_text(prompt)
    desc_emb = embed_text(description)
    score = cosine_similarity(prompt_emb, desc_emb) * 10
    return max(0, min(10, score))

# ------------------------------------------------------------
# Pipeline: Generates multiple images, rates them and selects the best one
# ------------------------------------------------------------

def image_gen_pipeline(article_summary: str, num_images: int = 2) -> str:
    """
    Image Generation Pipeline
    
    Pipeline that turns a news article summary (input) into an image (output).
    It uses the following steps and helper functions:
    1. Turn the news summary into an image generation prompt ("generate_image_prompt")
    2. Generate x (default: 2) images based on this prompt ("generate_image")
    3. Describe the generated images ("describe_image")
    4. Rate how well the descriptions match the prompt, using a scoring system based on cosine distance ("rate_image")
    5. Choose the image with the highest score
    6. Return the URL for this image
    """
    prompt = generate_image_prompt(article_summary)
    images = []
    ratings = []

    for i in range(num_images):
        image_url = generate_image(prompt)
        images.append(image_url)
        rating = rate_image(prompt, image_url)
        ratings.append(rating)

    best_index = ratings.index(max(ratings))
    best_image_url = images[best_index]
    return best_image_url

# ------------------------------------------------------------
# Tool Class
# ------------------------------------------------------------

class ImageGenerationTool(Tool):
    name = "image_generation_tool"
    description = """Generates an image based on a news article summary using the "image_gen_pipeline" function"""
    
    inputs = {
        "article_summary": {
            "type": "string",
            "description": "The news article summary to generate an image for."
        }
    }
    output_type = "string"

    def __init__(self):
        super().__init__()

    def forward(self, article_summary: str) -> str:
        return image_gen_pipeline(article_summary)

# ------------------------------------------------------------
# Example Usage
# ------------------------------------------------------------

if __name__ == "__main__":
    tool = ImageGenerationTool()
    summary = "AstraZeneca announces a new breakthrough in cancer research."
    url = tool.forward(summary)
    print("Generated image URL:", url)
