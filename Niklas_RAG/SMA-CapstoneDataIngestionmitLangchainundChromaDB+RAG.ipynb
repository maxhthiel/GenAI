{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d523ac87",
   "metadata": {},
   "source": [
    "# Data Ingestion mit Langchain und ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b42dd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import pandas as pd\n",
    "from langchain_openai import OpenAIEmbeddings # Embedding Modell\n",
    "from langchain_openai import ChatOpenAI  # Chat Modell\n",
    "from langchain_community.vectorstores import Chroma # Vektor-Datenbank\n",
    "from langchain_core.documents import Document # Für das Document Objekt\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter # Zum Aufteilen langer Texte in Chunks\n",
    "from dotenv import load_dotenv # Für das Laden des OpenAI APi Keys\n",
    "import os  #  für \"get .env\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "feda473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV laden\n",
    "df = pd.read_csv(\"nasdaq_100_final_for_RAG.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30cc5513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 103 entries, 0 to 102\n",
      "Data columns (total 27 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Ticker                  103 non-null    object \n",
      " 1   Company                 103 non-null    object \n",
      " 2   Long Business Summary   103 non-null    object \n",
      " 3   Sector (Yahoo)          102 non-null    object \n",
      " 4   Industry (Yahoo)        102 non-null    object \n",
      " 5   Country                 102 non-null    object \n",
      " 6   Market Cap              103 non-null    float64\n",
      " 7   Current Price           102 non-null    float64\n",
      " 8   52 Week High            103 non-null    float64\n",
      " 9   Average Monthly Return  102 non-null    float64\n",
      " 10  Previous Close          103 non-null    float64\n",
      " 11  Dividend Yield          60 non-null     float64\n",
      " 12  PE Ratio                95 non-null     float64\n",
      " 13  Forward PE              102 non-null    float64\n",
      " 14  PEG Ratio               0 non-null      float64\n",
      " 15  Price to Book           103 non-null    float64\n",
      " 16  Total Revenue           102 non-null    float64\n",
      " 17  Debt to Equity          96 non-null     float64\n",
      " 18  ROE                     97 non-null     float64\n",
      " 19  1y Return               102 non-null    float64\n",
      " 20  Volatility              102 non-null    float64\n",
      " 21  Website                 102 non-null    object \n",
      " 22  News Summary            103 non-null    object \n",
      " 23  Latest_News_Title       103 non-null    object \n",
      " 24  Latest_News_Link        103 non-null    object \n",
      " 25  Sentiment               103 non-null    object \n",
      " 26  Confidence              103 non-null    float64\n",
      "dtypes: float64(16), object(11)\n",
      "memory usage: 21.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f083a7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PEG Ratio ist leer. Diese Spalte kann ich löschen!\n",
    "df = df.drop(columns=[\"PEG Ratio\"])\n",
    "\n",
    "# Außerdem möchte ich keine \"nan\" Werte als Text in meinem RAG Dokument haben.\n",
    "df = df.fillna(\"\")  # <- alles, was NaN war, wird zum leeren String \n",
    "\n",
    "# Zahlen sollten außerdem Strings sein\n",
    "df = df.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1e6f88",
   "metadata": {},
   "source": [
    "Problem: Eine CSV ist KEIN embedding-fähiges Objekt. \n",
    "Eine Vektordatenbank erwartet einen langen erklärenden Text (Dokument) und eventuell Metadaten. Der Embedding-Encoder braucht einen einzigen, zusammenhängenden Text! \n",
    "--> Die Lösung: Spalten zusammenenfügen! Pro Zeile soll ein Text-Dokument erstellt werden. \n",
    "\n",
    "Problem 2: Zahlen \n",
    "Embeddings sind für semantischen Text optimiert. Ein RAG-System wandelt Text in Vektoren/Embeddings um. \n",
    "Reine Zahlen tragen wenig bis gar keine semantische Information. Und werden daher oft einfach nicht als relevant betrachtet. Im schlimmsten Fall „verrauschen“ die Embeddings durch viele Zahlenwerte.\n",
    "\n",
    "-->Lösung: Zahlen in den Metadaten speichern! \n",
    "Die Metadaten (z.B. Kennzahlen wie Market Cap, Current Price, PE Ratio, ROE,und die Website) werden aber nicht automatisch vom LLM erkannt, wenn das LLM nur den Text (page_content) bekommt.\n",
    "\n",
    "Die Zahlen aus den Metadaten können aber dynamisch in den Prompt eingefügt werden.\n",
    "\n",
    "Das LLM bekommt dann Text + Zahlen, ohne dass die Embeddings „verschmutzt“ werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95078028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='\n",
      "    Company: Apple Inc.  \n",
      "    Ticker: AAPL\n",
      "\n",
      "    Business Summary: Apple Inc. designs, manufactures, and markets smartphones, personal computers, tablets, wearables, and accessories worldwide. The company offers iPhone, a line of smartphones; Mac, a line of personal computers; iPad, a line of multi-purpose tablets; and wearables, home, and accessories comprising AirPods, Apple Vision Pro, Apple TV, Apple Watch, Beats products, and HomePod, as well as Apple branded and third-party accessories. It also provides AppleCare support and cloud services; and operates various platforms, including the App Store that allow customers to discover and download applications and digital content, such as books, music, video, games, and podcasts, as well as advertising services include third-party licensing arrangements and its own advertising platforms. In addition, the company offers various subscription-based services, such as Apple Arcade, a game subscription service; Apple Fitness+, a personalized fitness service; Apple Music, which offers users a curated listening experience with on-demand radio stations; Apple News+, a subscription news and magazine service; Apple TV, which offers exclusive original content and live sports; Apple Card, a co-branded credit card; and Apple Pay, a cashless payment service, as well as licenses its intellectual property. The company serves consumers, and small and mid-sized businesses; and the education, enterprise, and government markets. It distributes third-party applications for its products through the App Store. The company also sells its products through its retail and online stores, and direct sales force; and third-party cellular network carriers and resellers. The company was formerly known as Apple Computer, Inc. and changed its name to Apple Inc. in January 2007. Apple Inc. was founded in 1976 and is headquartered in Cupertino, California.\n",
      "\n",
      "    Sector: Technology\n",
      "    Industry: Consumer Electronics\n",
      "    Country: United States\n",
      "\n",
      "    Latest News:\n",
      "    Title: Apple’s presumptive future CEO, John Ternus, has a tough act to follow\n",
      "    Summary: Replacing Tim Cook, who has been at Apple since Steve Jobs hired him in 1998, will be a tall task.\n",
      "    Sentiment: negative\n",
      "' metadata={'ticker': 'AAPL', 'company': 'Apple Inc.', 'sector': 'Technology', 'industry': 'Consumer Electronics', 'country': 'United States', 'market_cap': '3490740525701.5293', 'current_price': '235.218936', 'previous_close': '230.679', '52_week_high': '277.32', 'avg_monthly_return': '0.0151192953395881', 'dividend_yield': '0.38', 'pe_ratio': '36.344044', 'forward_pe': '32.670273', 'price_to_book': '54.39591', 'total_revenue': '360561895224.1152', 'debt_to_equity': '152.411', 'roe': '1.7142199', 'return_1y': '0.0890419016609136', 'volatility': '0.0711340459703833', 'sentiment': 'negative', 'confidence': '0.4998730719089508', 'news_link': 'https://finance.yahoo.com/news/apples-presumptive-future-ceo-john-ternus-has-a-tough-act-to-follow-153029595.html', 'latest_news_title': 'Apple’s presumptive future CEO, John Ternus, has a tough act to follow', 'news_summary': 'Replacing Tim Cook, who has been at Apple since Steve Jobs hired him in 1998, will be a tall task.', 'website': 'https://www.apple.com'}\n"
     ]
    }
   ],
   "source": [
    "# Strukturierung der Daten für RAG\n",
    "\n",
    "#  Zeilen werden in ein Dokument umgewandelt\n",
    "def row_to_document(row):\n",
    "\n",
    "# row[\"Spaltenname\"] gibt den Wert der Spalte für diese Zeile zurück.\n",
    "# Alles, was zwischen den Triple-Quotes (f\"\"\"    \"\"\"\") steht, wird  übernommen. \n",
    "# Das Ergebnis ist dann ein formatierter Text, der alle wichtigen Informationen aus dieser Zeile enthält.\n",
    "    text = f\"\"\"\n",
    "    Company: {row[\"Company\"]}  \n",
    "    Ticker: {row[\"Ticker\"]}\n",
    "\n",
    "    Business Summary: {row[\"Long Business Summary\"]}\n",
    "\n",
    "    Sector: {row[\"Sector (Yahoo)\"]}\n",
    "    Industry: {row[\"Industry (Yahoo)\"]}\n",
    "    Country: {row[\"Country\"]}\n",
    "\n",
    "    Latest News:\n",
    "    Title: {row[\"Latest_News_Title\"]}\n",
    "    Summary: {row[\"News Summary\"]}\n",
    "    Sentiment: {row[\"Sentiment\"]}\n",
    "\"\"\"\n",
    "\n",
    "    metadata = {  # Diese Metadaten sind reine Zahlen oder Links, die das LLM nicht automatisch aus dem Text extrahieren würde.\n",
    "        \"ticker\": row[\"Ticker\"],\n",
    "        \"company\": row[\"Company\"],\n",
    "        \"sector\": row[\"Sector (Yahoo)\"],\n",
    "        \"industry\": row[\"Industry (Yahoo)\"],\n",
    "        \"country\": row[\"Country\"],\n",
    "        \"market_cap\": row[\"Market Cap\"],\n",
    "        \"current_price\": row[\"Current Price\"],\n",
    "        \"previous_close\": row[\"Previous Close\"],\n",
    "        \"52_week_high\": row[\"52 Week High\"],\n",
    "        \"avg_monthly_return\": row[\"Average Monthly Return\"],\n",
    "        \"dividend_yield\": row[\"Dividend Yield\"],\n",
    "        \"pe_ratio\": row[\"PE Ratio\"],\n",
    "        \"forward_pe\": row[\"Forward PE\"],\n",
    "        \"price_to_book\": row[\"Price to Book\"],\n",
    "        \"total_revenue\": row[\"Total Revenue\"],\n",
    "        \"debt_to_equity\": row[\"Debt to Equity\"],\n",
    "        \"roe\": row[\"ROE\"],\n",
    "        \"return_1y\": row[\"1y Return\"],\n",
    "        \"volatility\": row[\"Volatility\"],\n",
    "        \"sentiment\": row[\"Sentiment\"],\n",
    "        \"confidence\": row[\"Confidence\"],\n",
    "        \"news_link\": row[\"Latest_News_Link\"],\n",
    "        \"latest_news_title\":row[\"Latest_News_Title\"],\n",
    "        \"news_summary\": row[\"News Summary\"],\n",
    "        \"website\": row[\"Website\"], \n",
    "    }\n",
    "\n",
    "    return Document(page_content=text, metadata=metadata)  # Document ist ein Objekt aus LangChain.Es speichert den Text (page content) und die Metadaten. \n",
    "# Der zusammenhängende Text (page_content) wird später der in Embeddings umgewandelt. Metadaten werden später im dynamischen Prompting verwendet.\n",
    "\n",
    "# Alle Dokumente erstellen\n",
    "docs = [row_to_document(row) for i, row in df.iterrows()] # iteriert über alle Zeilen im DataFrame df. Für jede Zeile wird die Funktion row_to_document aufgerufen, um ein Document-Objekt zu erstellen. Das Ergebnis ist eine Liste von Document-Objekten, die in docs gespeichert wird.\n",
    "\n",
    "\n",
    "print(docs[0]) # Zeigt das erste Document in der Liste docs an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95bcbeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitter konfigurieren\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=50) # Max. Zeichen pro Chunk, Überlappung zwischen Chunks, um Kontextverlust zu vermeiden    \n",
    "\n",
    "# leere Liste für die gesplitteten Dokumente\n",
    "chunked_docs = [] \n",
    "\n",
    "for doc in docs: # Ich benutze eine For Schleife, weil ich eine Liste mit Dokumenten habe.\n",
    "    # Text in Chunks splitten\n",
    "    chunks = text_splitter.split_text(doc.page_content) # doc.page_content, weil ich die metadaten beibehalten möchte. \n",
    "    # --> Das Ergebnis ist eine Liste von Strings (Chunks)\n",
    "    \n",
    "    # Für jeden Chunk ein neues Document erstellen, Metadaten übernehmen.  So hat jeder Chunk des page_contents die gleichen Metadaten\n",
    "    for chunk in chunks:\n",
    "        chunked_docs.append(Document(page_content=chunk, metadata=doc.metadata)) # Jedes Document wird in die Liste chunked_docs hinzugefügt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "251ba074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ich möchte text-embedding-3-small von OpenAI verwenden. Dafür brauche ich meinen API Key, den ich in einer .env habe. \n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# .env Datei laden\n",
    "load_dotenv()\n",
    "\n",
    "# Key holen\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a73f562",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")  # Auswahl des Embedding Modells\n",
    "\n",
    "# Chroma-Datenbank erstellen\n",
    "db = Chroma.from_documents(documents=chunked_docs, embedding=embeddings, collection_name=\"nasdaq_docs\") \n",
    "#  Chroma Vektor-Datenbank aus den gesplitteten Dokumenten (chunked_docs) und den Embeddings. Der Name der Sammlung ist \"nasdaq_docs\".\n",
    "# Die Metadaten werden zusammen mit jedem Chunk in der Chroma-Datenbank gespeichert. (passiert automatisch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd568045",
   "metadata": {},
   "source": [
    "# Retrieval, Generate und Testen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e2c1a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from typing import TypedDict, List\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "from typing import Annotated\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edd48681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM Definieren\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0) # Temperature 0 sorgt dafür, dass mein LLM nicht halluziniert. (Nur hohe Wahrscheinlichkeiten werden als Antworten ausgegeben)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "224a3a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(search_kwargs={\"k\": 4}) # Kritisch! K = 1 ist perfekt, wenn ich eine Aktie Analysieren möchte. \n",
    "#Wenn ich aber Aktien vergleichen will, dann wäre ein anderes K besser.  \n",
    "\n",
    "# Ich habe an dieser stelle auch viel rumprobiert. z.B. mit Reranking oder Agentic (Vorgelagerter Knoten, der entscheided ob er ein Retriever mit k =1 oder einen mit k = 6 benutzt) \n",
    "# Das ergebnis war aber nicht besser als einfach K auf 5 zu setzen.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2b014ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG Graph erstellen      \n",
    "class RAGState(TypedDict):  # Definiert die Datenstruktur  für den Graphen.\n",
    "    input: str              # Feld für die ursprüngliche Benutzerfrage (ein String).\n",
    "    chat_history: List[BaseMessage] # Feld für den Chat-Verlauf (eine Liste von BaseMessage-Objekten).\n",
    "    context: List[Document] # Feld für die abgerufenen Daten (eine Liste von Dokument-Objekten).\n",
    "    answer: str             # Feld für die finale Antwort des LLM (ein String)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "551580a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformulate_query(state):\n",
    "    if not state.get(\"chat_history\"): \n",
    "        return state # Abbruch, falls kein Verlauf existiert\n",
    "    \n",
    "    # Prompt definieren: System-Befehl, Verlauf-Platzhalter, User-Frage\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Formuliere die Frage so um, dass sie ohne Verlauf verständlich ist (Namen statt Pronomen). Nur die Frage.\"), # Anweisung\n",
    "        MessagesPlaceholder(\"history\"), # Fügt Chat-Verlauf ein\n",
    "        (\"human\", \"{input}\") # Aktuelle User-Frage\n",
    "    ])\n",
    "\n",
    "    # Chain (Prompt -> LLM -> Text) erstellen und direkt ausführen\n",
    "    new_query = (prompt | llm | StrOutputParser()).invoke({\"history\": state[\"chat_history\"], \"input\": state[\"input\"]}) # Generierung\n",
    "    \n",
    "    state[\"input\"] = new_query # Überschreibt die vage Frage mit der präzisen\n",
    "    return state # Gibt aktualisierten State zurück"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79f1834e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve \n",
    "def retrieve(state): # Definiert den 'retrieve'-Knoten für den LangGraph. --> erhält den aktuellen \"Zustand\" (state). \n",
    "    docs = retriever.invoke(state[\"input\"]) # Ruft das die Vektor-Datenbank) auf. --> und nutzt die Nutzeranfrage (state[\"input\"]), um die relevantesten Dokumente zu finden.\n",
    "    state[\"context\"] = docs # Speichert die *kompletten* Dokumente (Text + Metadaten) und nicht nur den Text (doc.page_content for doc in docs).\n",
    "    return state # Gibt den aktualisierten Zustand zurück."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30157c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definiert den 'generate'-Knoten für den LangGraph. Die Funktion erhält ein state-Objekt als Eingabe\n",
    "def generate(state):\n",
    "\n",
    "    docs = state[\"context\"]  # abgerufene Dokumente aus dem Zustand holen\n",
    "    history = state.get(\"chat_history\", []) #\n",
    "\n",
    "    # Liste für die Kontext-Blöcke, die an das LLM übergeben werden\n",
    "    prompt_blocks = []\n",
    "\n",
    "    for doc in docs:  # Für jedes Dokument einen eigenen Block bauen\n",
    "        block = \"\" # leerer String \n",
    "\n",
    "        # Textinhalt des Dokuments \n",
    "        block += doc.page_content + \"\\n\\n\"\n",
    "\n",
    "        # Alle  relevanten Metadaten (Kennzahlen) strukturiert hinzufügen\n",
    "        block += \"Finanzkennzahlen & Metadaten\\n\"\n",
    "        block += f\"Ticker: {doc.metadata.get('ticker', '')}, Unternehmen: {doc.metadata.get('company', '')}\\n\"\n",
    "        block += f\"Sektor: {doc.metadata.get('sector', '')}, Industrie: {doc.metadata.get('industry', '')}\\n\"\n",
    "        block += f\"Marktkapitalisierung: {doc.metadata.get('market_cap', '')}\\n\"\n",
    "        block += f\"Aktueller Kurs: {doc.metadata.get('current_price', '')}, Vortagesschluss: {doc.metadata.get('previous_close', '')}, 52-Wochen-Hoch: {doc.metadata.get('52_week_high', '')}\\n\"\n",
    "        block += f\"KGV (PE Ratio): {doc.metadata.get('pe_ratio', '')}, KGV (Forward PE): {doc.metadata.get('forward_pe', '')}\\n\"\n",
    "        block += f\"Dividendenrendite: {doc.metadata.get('dividend_yield', '')}, Kurs-Buchwert-Verhältnis (PB): {doc.metadata.get('price_to_book', '')}\\n\"\n",
    "        block += f\"Gesamtumsatz: {doc.metadata.get('total_revenue', '')}, Verschuldungsgrad (Debt/Equity): {doc.metadata.get('debt_to_equity', '')}\\n\"\n",
    "        block += f\"Eigenkapitalrendite (ROE): {doc.metadata.get('roe', '')}, 1-Jahres-Rendite: {doc.metadata.get('return_1y', '')}, durchschnittliche monatl. Rendite der letzten 5 jahre: {doc.metadata.get('avg_monthly_return', '')}\\n\"\n",
    "        block += f\"Volatilität: {doc.metadata.get('volatility', '')}, Link zur Webseite: {doc.metadata.get('website', '')}\\n\\n\"\n",
    "        block += f\"Nachrichten Titel: {doc.metadata.get('latest_news_title', '')}, Bewertung der News: {doc.metadata.get('sentiment', '')}, Link zur News: {doc.metadata.get('news_link', '')}\\n\"\n",
    "        block += f\"Inhalt: {doc.metadata.get('news_summary', '')}\\n\"\n",
    "\n",
    "        prompt_blocks.append(block)  # kompletten Block in die Liste packen\n",
    "\n",
    "    # finalen Promptkontext bauen\n",
    "    context = \"\\n\\n\".join(prompt_blocks) # Liste von Strings (Text + Metadaten) = prompt_blocks, join verbindet alle Strings in der Liste zu einem einzigen String, \n",
    "\n",
    "    # Wie in der Demo (Prompt Engineering) # Das LLM checkt sonst z.B. nicht, dass ich die Zahlen in Euro umgeandelt habe!\n",
    "    messages = [{\"role\": \"system\",\"content\": ( \"You are a helpful financial assistant who answers questions based on the given context. Analyze all financial data and metadata carefully. Bei den Kennzahlen handelt es sich um EURO\")\n",
    "        },*history,{\"role\": \"user\", \"content\": f\"Context:\\n{context}\\n\\nQuestion: {state['input']}\"}]\n",
    "\n",
    "    # LLM Aufruf\n",
    "    answer = llm.invoke(messages)\n",
    "\n",
    "    new_history = history + [\n",
    "        HumanMessage(content=state[\"input\"]),\n",
    "        AIMessage(content=answer.content)\n",
    "    ]\n",
    "\n",
    "    return {\n",
    "        \"answer\": answer.content, \n",
    "        \"chat_history\": new_history \n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da9f3c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG Graph zusammenbauen \n",
    "rag = (\n",
    "    StateGraph(RAGState)\n",
    "    .add_node(\"reformulate\", reformulate_query) # Chateingabe Umschreiben mit Chathistory, wenn vorhanden\n",
    "    .add_node(\"retrieve\", retrieve) # Dann Retrieve\n",
    "    .add_node(\"generate\", generate) # Dann Generate\n",
    "    \n",
    "    # Ablauf: Erst Umschreiben -> Dann Suchen -> Dann Antworten\n",
    "    .set_entry_point(\"reformulate\") # Startknoten ist reformulate \n",
    "    .add_edge(\"reformulate\", \"retrieve\") # verbindet reformulate mit retrieve\n",
    "    .add_edge(\"retrieve\", \"generate\") # verbindet retrieve mit generate \n",
    "    .add_edge(\"generate\", END) # Endknoten\n",
    "    .compile() # Kompiliert den Graphen\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1bf3cd",
   "metadata": {},
   "source": [
    "Testen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49b684d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globale Variable (für den Chat-Verlauf)\n",
    "global_chat_history = []\n",
    "\n",
    "def ask(question):\n",
    "    \"\"\"\n",
    "    Die letzten 4 Nachrichten werden als Gedächtnis genutzt. \n",
    "    \"\"\"\n",
    "    global global_chat_history\n",
    "    \n",
    "    # 1. Graph aufrufen\n",
    "    result = rag.invoke({\n",
    "        \"input\": question, \n",
    "        \"chat_history\": global_chat_history # Übergibt den aktuellen Verlauf an den Graphen, welcher dann mit reformulate startet! Reformulate bekommt also die Chatnachrichten und die aktuelle Frage. Und erst dann wird im Rag gesucht!\n",
    "    })\n",
    "    \n",
    "    # 2. Gedächtnis aktualisieren. Nur die letzten 4 Nachrichten werden genutzt. So wirde der Input nicht viel viel zu lang.\n",
    "    global_chat_history = result[\"chat_history\"][-4:]\n",
    "    \n",
    "    # 3. Antwort ausgeben\n",
    "    print(f\"{result['answer']}\\n\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d86490d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today with financial information or analysis?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ask(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08f054c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Aktie von Nvidia (Ticker: NVDA) gehört zum Technologiesektor und zur Halbleiterindustrie. Hier sind einige wichtige Finanzkennzahlen und Metadaten für Nvidia:\n",
      "\n",
      "1. Marktkapitalisierung: 3.766.828.814.617,80 EURO\n",
      "2. Aktueller Kurs: 154,98 EURO\n",
      "3. Vortagesschlusskurs: 156,51 EURO\n",
      "4. 52-Wochen-Hoch: 212,19 EURO\n",
      "5. Kurs-Gewinn-Verhältnis (KGV): 44,28\n",
      "6. KGV (Forward PE): 43,42\n",
      "7. Dividendenrendite: 0,02\n",
      "8. Kurs-Buchwert-Verhältnis (PB): 36,57\n",
      "9. Gesamtumsatz: 162.139.825.805,72 EURO\n",
      "10. Verschuldungsgrad (Debt/Equity): 8,82\n",
      "11. Eigenkapitalrendite (ROE): 1,07\n",
      "12. 1-Jahres-Rendite: 33,24%\n",
      "13. Durchschnittliche monatliche Rendite der letzten 5 Jahre: 5,59%\n",
      "14. Volatilität: 14,76%\n",
      "15. Webseite: [Nvidia Webseite](https://www.nvidia.com)\n",
      "\n",
      "Zusätzlich gibt es eine neutrale Nachricht mit dem Titel \"Crucial Black Friday, AI bubble worries and Fed rate cut hopes\", die auf Yahoo Finance veröffentlicht wurde. Die Nachricht diskutiert die Auswirkungen des Black Friday auf die Märkte sowie die Bedenken hinsichtlich einer AI-Blase und der Hoffnungen auf Zinssenkungen durch die Fed.\n",
      "\n",
      "Insgesamt scheint Nvidia solide Finanzkennzahlen aufzuweisen, mit einer guten Eigenkapitalrendite und einer positiven 1-Jahres-Rendite. Die Aktie hat in den letzten 5 Jahren eine durchschnittliche monatliche Rendite von 5,59% erzielt. Die Volatilität der Aktie beträgt 14,76%, was auf eine gewisse Schwankungsanfälligkeit hinweisen könnte. Es ist wichtig, die aktuellen Nachrichten und Entwicklungen im Auge zu behalten, um fundierte Anlageentscheidungen zu treffen.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# testen\n",
    "ask(\"Analysiere die Aktie Nvidea\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10242326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die aktuelle News zu Nvidia ist positiv zu bewerten. Der Titel der Nachricht lautet \"Top Semiconductor Stocks. Nvidia, AMD, Intel Poised for AI Growth\", und die Zusammenfassung besagt, dass eine \"AI Spending Frenzy Sparks Chip Rally\" ausgelöst wurde und Nvidia weiterhin eine wichtige Position bei Investoren innehat. Der Sentiment-Wert für diese Nachricht ist ebenfalls als positiv angegeben.\n",
      "\n",
      "Diese positive Einschätzung wird durch die Tatsache unterstützt, dass Nvidia im Technologiesektor und in der Halbleiterindustrie tätig ist, was aufgrund des wachsenden Interesses an künstlicher Intelligenz (AI) und der steigenden Nachfrage nach Halbleiterlösungen eine vielversprechende Position darstellt. Insgesamt deutet die News darauf hin, dass Nvidia gut positioniert ist, um vom erwarteten Wachstum im Bereich der künstlichen Intelligenz zu profitieren.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testet das Gedächtnis.\n",
    "ask(\"Ist die aktuelle News zu diesem Unternehmen eher positiv oder negativ zu bewerten?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2aa8fc",
   "metadata": {},
   "source": [
    "Man könnte es auch einfach ohne Graph machen und eine semantische Suche durchführen. Hier könnte man aber nicht genau steuern was passiert. Es wäre Linear und nicht modular.\n",
    "Man hätte die Chat History anders einbauen müssen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e07f5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG Test abfrage:\n",
    "# llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "# query = \"Analysiere Apple, gehe auch auf aktuelle News ein. Sind diese Positiv oder negativ für die Aktie?\"\n",
    "\n",
    "# Top-k relevante Chunks abrufen\n",
    "# results = db.similarity_search(query, k=1)\n",
    "\n",
    "# Dieser Block nutzt jetzt alle relevanten Metadaten\n",
    "# prompt_context = \"\"\n",
    "# for doc in results:\n",
    "    # 1. Semantischer Text-Inhalt\n",
    "    #prompt_context += doc.page_content + \"\\n\"\n",
    "    \n",
    "    # 2. Alle relevanten Metadaten strukturiert hinzufügen\n",
    "    #prompt_context += f\"--- Finanzkennzahlen & Metadaten ---\\n\"\n",
    "    #prompt_context += f\"Ticker: {doc.metadata['ticker']}, Unternehmen: {doc.metadata['company']}\\n\"\n",
    "    #prompt_context += f\"Sektor: {doc.metadata['sector']}, Industrie: {doc.metadata['industry']}\\n\"\n",
    "    #prompt_context += f\"Marktkapitalisierung: {doc.metadata['market_cap']}\\n\"\n",
    "    #prompt_context += f\"Aktueller Kurs: {doc.metadata['current_price']}, Vortagesschluss: {doc.metadata['previous_close']}\\n\"\n",
    "    #prompt_context += f\"KGV (PE Ratio): {doc.metadata['pe_ratio']}, KGV (Forward PE): {doc.metadata['forward_pe']}\\n\"\n",
    "    #prompt_context += f\"Dividendenrendite: {doc.metadata['dividend_yield']}, Kurs-Buchwert-Verhältnis (PB): {doc.metadata['price_to_book']}\\n\"\n",
    "    #prompt_context += f\"Gesamtumsatz: {doc.metadata['total_revenue']}, Verschuldungsgrad (Debt/Equity): {doc.metadata['debt_to_equity']}\\n\"\n",
    "    #prompt_context += f\"Eigenkapitalrendite (ROE): {doc.metadata['roe']}, 1-Jahres-Rendite: {doc.metadata['return_1y']}\\n\"\n",
    "    #prompt_context += f\"Volatilität: {doc.metadata['volatility']}, Link zur Webseite: {doc.metadata['website']}\\n\\n\"\n",
    "    #prompt_context += f\"Nachrichten Titel: {doc.metadata['latest_news_title']}, Medienstimmung diesbezüglich: {doc.metadata['sentiment']}, Link zur News: {doc.metadata['news_link']}\\n\"\n",
    "\n",
    "#prompt = f\"\"\"\n",
    "#Nutze die folgenden Informationen, um eine Analyse zu erstellen. \n",
    "#Berücksichtige sowohl den beschreibenden Text als auch die detaillierten Kennzahlen:\n",
    "\n",
    "#{prompt_context}\n",
    "#\"\"\"\n",
    "\n",
    "# Korrekter Aufruf mit .invoke()\n",
    "#response = llm.invoke(prompt) \n",
    "\n",
    "#print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SMA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
